{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1de6c9-4dcf-4b49-83c7-f2011cab201c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/07 16:32:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "# Initialize Spark Session (this code remains unchanged as requested)\n",
    "spark_session = SparkSession.builder\\\n",
    "        .master(\"spark://spark-master:7077\") \\\n",
    "        .appName(\"test2_Junming_Ma\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\", \"30s\")\\\n",
    "        .config(\"spark.executor.cores\", 2)\\\n",
    "        .config(\"spark.driver.port\", 9999)\\\n",
    "        .config(\"spark.blockManager.port\", 10005)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Use the RDD API via spark_context\n",
    "spark_context = spark_session.sparkContext\n",
    "spark_context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6071d9d5-8c0c-4254-901f-6e1fea4c965c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line of file: ['{\"author\":\"raysofdarkmatter\",\"body\":\"I think it should be fixed on either UTC standard or UTC+1 year around, with the current zone offsets.\\\\n\\\\nMoving timescales add a lot of complexity to the implementation of timekeeping systems and have [dubious value]( \\\\n\\\\nI think seasonal shifting time made sense in the pre-electric past, when timekeeping was more flexible and artificial light was inefficient and often dangerous. \\\\n\\\\nNow we have machines that work easily with simple timekeeping rules, and it\\'s more beneficial to spend a small amount on energy for lighting, and save the larger cost of engineering things to work with the complex timekeeping rules, as well as saving the irritation to humans.\\\\n\\\\nLighting has gotten much more efficient over time; we can squeeze out a lot more photons per unit of energy from a 2012 CFL or LED than a candle could in 1780, or a lightbulb could in 1950. \\\\n\\\\nThere\\'s a lot of room for improvement in how we use lights as well; as lighting control gets more intelligent, there will be a lot of savings from not illuminating inactive spaces constantly.\\\\n\\\\ntl;dr: Shifting seasonal time is no longer worth it.\",\"normalizedBody\":\"I think it should be fixed on either UTC standard or UTC+1 year around, with the current zone offsets. \\\\n Moving timescales add a lot of complexity to the implementation of timekeeping systems and have [dubious value]( \\\\n I think seasonal shifting time made sense in the pre-electric past, when timekeeping was more flexible and artificial light was inefficient and often dangerous. \\\\n Now we have machines that work easily with simple timekeeping rules, and it\\'s more beneficial to spend a small amount on energy for lighting, and save the larger cost of engineering things to work with the complex timekeeping rules, as well as saving the irritation to humans. \\\\n Lighting has gotten much more efficient over time; we can squeeze out a lot more photons per unit of energy from a 2012 CFL or LED than a candle could in 1780, or a lightbulb could in 1950. \\\\n There\\'s a lot of room for improvement in how we use lights as well; as lighting control gets more intelligent, there will be a lot of savings from not illuminating inactive spaces constantly. \\\\n tl;dr: Shifting seasonal time is no longer worth it. \\\\n\",\"content\":\"I think it should be fixed on either UTC standard or UTC+1 year around, with the current zone offsets. \\\\n Moving timescales add a lot of complexity to the implementation of timekeeping systems and have [dubious value]( \\\\n I think seasonal shifting time made sense in the pre-electric past, when timekeeping was more flexible and artificial light was inefficient and often dangerous. \\\\n Now we have machines that work easily with simple timekeeping rules, and it\\'s more beneficial to spend a small amount on energy for lighting, and save the larger cost of engineering things to work with the complex timekeeping rules, as well as saving the irritation to humans. \\\\n Lighting has gotten much more efficient over time; we can squeeze out a lot more photons per unit of energy from a 2012 CFL or LED than a candle could in 1780, or a lightbulb could in 1950. \\\\n There\\'s a lot of room for improvement in how we use lights as well; as lighting control gets more intelligent, there will be a lot of savings from not illuminating inactive spaces constantly.\",\"content_len\":178,\"summary\":\"Shifting seasonal time is no longer worth it.\",\"summary_len\":8,\"id\":\"c69al3r\",\"subreddit\":\"math\",\"subreddit_id\":\"t5_2qh0n\"}']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Load the dataset from HDFS\n",
    "DATA_PATH = 'data/reddit.json'\n",
    "lines = spark_context.textFile(f\"hdfs://spark-master:9000/{DATA_PATH}\")\n",
    "print(\"First line of file:\", lines.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adcaa97d-a67c-4f95-8e30-86b4104137da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed first record: [{'author': 'raysofdarkmatter', 'body': \"I think it should be fixed on either UTC standard or UTC+1 year around, with the current zone offsets.\\n\\nMoving timescales add a lot of complexity to the implementation of timekeeping systems and have [dubious value]( \\n\\nI think seasonal shifting time made sense in the pre-electric past, when timekeeping was more flexible and artificial light was inefficient and often dangerous. \\n\\nNow we have machines that work easily with simple timekeeping rules, and it's more beneficial to spend a small amount on energy for lighting, and save the larger cost of engineering things to work with the complex timekeeping rules, as well as saving the irritation to humans.\\n\\nLighting has gotten much more efficient over time; we can squeeze out a lot more photons per unit of energy from a 2012 CFL or LED than a candle could in 1780, or a lightbulb could in 1950. \\n\\nThere's a lot of room for improvement in how we use lights as well; as lighting control gets more intelligent, there will be a lot of savings from not illuminating inactive spaces constantly.\\n\\ntl;dr: Shifting seasonal time is no longer worth it.\", 'normalizedBody': \"I think it should be fixed on either UTC standard or UTC+1 year around, with the current zone offsets. \\n Moving timescales add a lot of complexity to the implementation of timekeeping systems and have [dubious value]( \\n I think seasonal shifting time made sense in the pre-electric past, when timekeeping was more flexible and artificial light was inefficient and often dangerous. \\n Now we have machines that work easily with simple timekeeping rules, and it's more beneficial to spend a small amount on energy for lighting, and save the larger cost of engineering things to work with the complex timekeeping rules, as well as saving the irritation to humans. \\n Lighting has gotten much more efficient over time; we can squeeze out a lot more photons per unit of energy from a 2012 CFL or LED than a candle could in 1780, or a lightbulb could in 1950. \\n There's a lot of room for improvement in how we use lights as well; as lighting control gets more intelligent, there will be a lot of savings from not illuminating inactive spaces constantly. \\n tl;dr: Shifting seasonal time is no longer worth it. \\n\", 'content': \"I think it should be fixed on either UTC standard or UTC+1 year around, with the current zone offsets. \\n Moving timescales add a lot of complexity to the implementation of timekeeping systems and have [dubious value]( \\n I think seasonal shifting time made sense in the pre-electric past, when timekeeping was more flexible and artificial light was inefficient and often dangerous. \\n Now we have machines that work easily with simple timekeeping rules, and it's more beneficial to spend a small amount on energy for lighting, and save the larger cost of engineering things to work with the complex timekeeping rules, as well as saving the irritation to humans. \\n Lighting has gotten much more efficient over time; we can squeeze out a lot more photons per unit of energy from a 2012 CFL or LED than a candle could in 1780, or a lightbulb could in 1950. \\n There's a lot of room for improvement in how we use lights as well; as lighting control gets more intelligent, there will be a lot of savings from not illuminating inactive spaces constantly.\", 'content_len': 178, 'summary': 'Shifting seasonal time is no longer worth it.', 'summary_len': 8, 'id': 'c69al3r', 'subreddit': 'math', 'subreddit_id': 't5_2qh0n'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 1. Parse the JSON Lines\n",
    "# ------------------------------\n",
    "def parse_json(line):\n",
    "    try:\n",
    "        return json.loads(line)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "parsed_rdd = lines.map(parse_json).filter(lambda x: x is not None)\n",
    "print(\"Parsed first record:\", parsed_rdd.take(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f45a55e-f9e0-4cfe-a68f-ea1f9d3d7a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/07 16:33:48 ERROR TransportClient: Failed to send RPC RPC 5058954677989605909 to /192.168.2.135:45648: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "25/03/07 16:33:48 ERROR TransportClient: Failed to send RPC RPC 6620663130107817154 to /192.168.2.135:45648: io.netty.channel.StacklessClosedChannelException\n",
      "io.netty.channel.StacklessClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(Object, ChannelPromise)(Unknown Source)\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments: 3848330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:======================================================>(146 + 1) / 147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing 'body': 0\n",
      "Missing 'author': 0\n",
      "Missing 'subreddit': 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Total number of comments\n",
    "total_comments = parsed_rdd.count()\n",
    "print(\"Total comments:\", total_comments)\n",
    "\n",
    "# Function to check if a field is missing or empty\n",
    "def missing_value(record, field):\n",
    "    return (field not in record) or (record[field] is None) or (record[field] == \"\")\n",
    "\n",
    "# Count missing values in key fields: 'body', 'author', 'subreddit'\n",
    "missing_body = parsed_rdd.filter(lambda r: missing_value(r, \"body\")).count()\n",
    "missing_author = parsed_rdd.filter(lambda r: missing_value(r, \"author\")).count()\n",
    "missing_subreddit = parsed_rdd.filter(lambda r: missing_value(r, \"subreddit\")).count()\n",
    "\n",
    "print(\"Missing 'body':\", missing_body)\n",
    "print(\"Missing 'author':\", missing_author)\n",
    "print(\"Missing 'subreddit':\", missing_subreddit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29038a59-7843-48b7-8b18-046e9fb4d491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=====================================================> (143 + 4) / 147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment Length Stats:\n",
      "  Count: 3848330\n",
      "  Mean: 1622.758239548064\n",
      "  Stdev: 1542.569038521586\n",
      "  Min: 12\n",
      "  Max: 40216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#Comment Length Analysis\n",
    "# ------------------------------\n",
    "# Compute the length of each comment (based on 'body')\n",
    "comment_lengths = parsed_rdd.map(lambda r: len(r.get(\"body\", \"\")))\n",
    "length_stats = comment_lengths.stats()  # Returns count, mean, stdev, min, max\n",
    "print(\"Comment Length Stats:\")\n",
    "print(\"  Count:\", length_stats.count())\n",
    "print(\"  Mean:\", length_stats.mean())\n",
    "print(\"  Stdev:\", length_stats.stdev())\n",
    "print(\"  Min:\", length_stats.min())\n",
    "print(\"  Max:\", length_stats.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5026da7-93ca-40e2-9c72-7962fde38eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:===================================>                   (94 + 48) / 147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Subreddits by comment count:\n",
      "   AskReddit 589947\n",
      "   relationships 352049\n",
      "   leagueoflegends 109307\n",
      "   tifu 52219\n",
      "   relationship_advice 50416\n",
      "   trees 47286\n",
      "   gaming 43851\n",
      "   atheism 43268\n",
      "   AdviceAnimals 40783\n",
      "   funny 40171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Count comments per subreddit\n",
    "subreddit_counts = parsed_rdd.map(lambda r: (r.get(\"subreddit\", \"unknown\"), 1)) \\\n",
    "                             .reduceByKey(add)\n",
    "top_subreddits = subreddit_counts.takeOrdered(10, key=lambda x: -x[1])\n",
    "print(\"Top 10 Subreddits by comment count:\")\n",
    "for sub, cnt in top_subreddits:\n",
    "    print(\"  \", sub, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8afda6-114f-4723-8aa7-efcfe09fe016",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
